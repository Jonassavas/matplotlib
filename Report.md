# Report for assignment 3

## Project:

Name: Matplotlib

URL: https://github.com/matplotlib/matplotlib

Matplotlib is a Python library for creating static, animated, and interactive visualizations.

## 3.3 Onboarding: 
#### 1. How easily can you build the project? Briefly describe if everything worked as documented or not:
a) Yes, the project requires a lot of dependencies with a provided developer guide to install and build the project.  

b) The tools are mostly well documented with a dedicated website. However, many of the functions have limited documentation where no guidance is provided while some functions have incredibly detailed comments that describe both the purpose of the function but also the intricacies of all of its arguments.  

c) The components were installed automatically from a list of dependencies but it required a few different steps with a virtual environment where these dependencies could be installed.  

d) The build concluded without errors for two of us in the group while three others did not manage to install all the dependencies and build the project.
The examples and tests run mostly as intended with very few tests failing out of about 8000 tests.

#### 2. Do you plan to continue or choose another project?  
We plan to continue with the matplotlib repository where we firstly choose an algorithm collection for python where the tests were very scarce and used an unfamiliar framework. Matplotlib was the first repo that somewhat worked for the group and we did not have time to change it for the time-frame of the assignment.


## 3.4 Part 1: Complexity measurement
#### 1. What are your results? Did everyone get the same result? Is there something that is unclear? If you have a tool, is its result the same as yours?
 
We used lizard to count the cyclomatic complexity. The table below includes the the initial lizard results for our 10 chosen functions and the entire list can be found [here](./lib/matplotlib/lizardInitRes.txt),  to all the functions.
The results were generated by running this command:  
`lizard ./ -x"./tests/*" -x"./testing/*" > lizardInitRes.txt`  
From the `./lib/matplotlib` directory which avoids the test-files. 

```
================================================
  NLOC    CCN   token  PARAM  length  location  
------------------------------------------------
//Jonas's functions
198     77   1724     17      462 hist@6492-6953@./axes/_axes.py
130     32    932      4      161 subsuper@2254-2414@./_mathtext.py
Manual calculation: subsuper()
PI = 37, s =  5 --> M = PI - s + 2 = 34

//Ronan's functions
64     15    353      9     152 figure@690-841@./pyplot.py
43      19    253      2      198 subplot@1127-1324@./pyplot.py
Manual calculation: subplot()
PI = 18, s = 1 --> M = PI - s + 2 = 19

//Ahmad's functions
94      35    673     28     309 boxplot@3713-4021@./axes/_axes.py
38      15    418      2      46 _apply_params@351-396@./axis.py

//Pontus's functions
57      17    431      8     108 get_tight_layout_figure@194-301@./_tight_layout.py
34      19    258      5      96 _parse_legend_args@1260-1355@./legend.py
Manual calculation: get_tight_layout_figure()
PI = 27 - 6 + 2 = 23 


//Klara's functions
119     30   1057     19     229 streamplot@18-246@./streamplot.py
35      16    252      2      35 _keypress@1463-1497@./widgets.py
Manual calculation results: _keypress()
PI = 15, s = 1, M = 15 - 1 + 2 = 16
```

The manual calculation was done through the algorithm from the lecture:
$$CCN = π - s + 2$$
where π = number of decisions (if, while, &&, ||) and s = number of exit points (return, throw).


The results with our own calculations seem to be a tiny bit off the results of lizard with the cyclomatic complexity number where these results are most likely due to our inexperience with counting this complexity and python-specific syntax that could be counted as a branch etc. 

#### 2. Are the functions/methods with high CC also very long in terms of LOC?
The functions with high CC are in most cases also very long in LOC but there are exceptions with shorter functions that involve a lot of branches. There are also functions with lots of lines which do not have a high CCN.

#### 3. What is the purpose of these functions? Is it related to the high CC?
##### Pontus: 
the function `get_tight_layout_figure()` returns a subplot parameter for tight-layouted-figure with specified padding. It has quite a few if statements to decide these parameters and to warn if the inputs are not safe and otherwise its for loops to initialize lists. I guess this is needed to compute the parameters so I would say it’s related.

The purpose of the function _parse_legend_args() is to get the handles and labels from the calls to either ``figure.legend`` or ``axes.legend``. To do this it needs to verify that the argos and handles are valid which is the cause of the high CCN.


##### Jonas: 

The purpose of the `hist()` function is to compute and plot a histogram by preparing the input data for use in the NumPy library as well as add additional functionality and customizations to the histogram plot with its various arguments. It is highly related to CC with what I would say a reasonable complexity number since a histogram can include various different arguments and allowing for various types of customization to the plotted histogram naturally requires a lot of branching in the code to perform the corresponding actions.

The purpose of the `subsuper()` function lacks any form of documentation within the code or on the dedicated website but with analysis of the code I assume that the function allows plots to include both subscripts and superscripts to correctly write the mathematical language. Its relation to CC seems very reasonable since it has to interact graphically with the plots and correctly perform the subscript and superscript to the provided text. 

##### Klara: 

The `streamplot()` function is the main function of its class and includes a lot of the basic functions of streamline plotting for 2D vector fields. In its documentation it is described to neither be complete or updated and is set as “will be updated in the future”, which is probably the explanation for it having a high complexity number.

The purpose of the `_keypress()` function in the widgets.py class is to handle key inputs to the widgets. This function basically consists of if-cases for all of the supported keypress cases and thus will naturally have a higher complexity.

##### Ahmad:

The `boxplot()`  function is for creating a box and whisker plot using the Matplotlib library. The function takes in several optional parameters that can be used to customize the plot, such as the position and width of the boxes, the appearance of the outliers, and the color and style of the plot elements.

The `_apply_params()` function sets various properties of an axis in a matplotlib plot, based on the keyword arguments passed to it. It first sets the visibility of various components of the axis, such as gridlines and tick lines, based on the "gridOn", "tick1On", "tick2On", "label1On", and "label2On" arguments.

##### Ronan: 

`figure()`: Create a new figure, or activate an existing figure. This function takes several parameters, such as num, figsize, dpi, facecolor, edgecolor, frameon, and FigureClass, which allow customization of the created or activated figure. The number of parameter to handle leads to the complexity of the function.

`Subplot()`: adds subplot to a current figure at the specified grid position.  It is similar to the `subplots()` function however unlike `subplots()` it adds one subplot at a time. So to create multiple plots you will need several lines of code with the `subplot()` function. The function had to check a lot of conditions too leading to a high complexity.



#### 4. If your programming language uses exceptions: Are they taken into account by the tool? If you think of an exception as another possible branch (to the catch block or the end of the function), how is the CC affected?
Python uses exceptions where the used tool for the cyclomatic complexity analysis, lizard, does take exceptions into account. We think of exceptions as termination operators such as a `return` statement where if-statements and loops where exceptions can potentially be thrown. 

#### 5. Is the documentation of the function clear about the different possible outcomes induced by different branches taken?
The documentation for the different functions are often very clear about the different possible outcomes induced by different branches whereas some functions completely lack documentation. For example, the `hist()` function fully describes its variables and its impact on the histogram whereas the `subsuper()` function completely lack documentation. 

## 3.5 Part 2: Coverage measurement & improvement
#### DIY tool questions:
#### 1. What is the quality of your own coverage measurement? Does it take into account ternary operators (condition ? yes : no) and exceptions, if available in your language?
The class for the implementation can be found [here](./lib/matplotlib/tests/conftest.py). The results of a boolean list for each of our five functions to a text file, found [here](./lib/matplotlib/BranchCovResOld.txt), when the unit-tests are completed. To set this up we manually instrument the function to include this boolean list and give each branch an index where they set the boolean to true if we ever enter the branch during the tests. 

It does consider ternary operators and exceptions when these boolean assignment instructions have been set in the function. 

#### 2. What are the limitations of your tool? How would the instrumentation change if you modify the program? 
The limitations of the tool are that it is solely up to the developer to manually set these list assignments within the function which could cause it to generate the wrong output and the drawbacks of having to add these list assignments naturally causes lower performance.

Changing the program to how we would like it to work would not require additional code to be inserted into the function and rather directly reading the file which we determined would take too much time for this assignment while the task only required manual instrumentation which is what this tool achieves. 

#### 3. If you have an automated tool, are your results consistent with the ones produced by existing tool(s)?
Yes, the tool we used, [coverage.py](https://coverage.readthedocs.io/en/7.1.0/), was accurate compared to the automated coverage tool where we could see which lines were not executed in an HTML format where the corresponding branches also indicated that they were not taken in our tool.

### 3.5.2 Task 2: Coverage improvement
1,2 Relates more to instructions for the task.
#### 3. Create new test cases as needed to improve branch coverage in the given functions. Can you call the function directly? Can you expand on existing tests? Do you have to add additional interfaces to the system (as public methods) to make it possible to set up test data structures?
The new tests to improve coverage could mostly be done by replicating existing tests and editing them to setup the arguments to reach different branches. Most of the functions require data structures and additional interfaces where a lot of inspiration could be drawn from the existing tests.

#### 4. If you have 100 % branch coverage, you can choose other functions or think about path coverage. You may cover all branches in a function, but what does this mean for the combination of branches? Consider the existing tests by hand and check how they cover the branches (in which combinations).
We changed functions when 100% branch coverage was achieved. Path coverage is the combination of branches taken in a particular function call which can drastically change the execution and the correctness of the output, but we only considered to achieve branch coverage in the tests as that was the requirement for the task.

### 3.5.3 Task 3: Refactoring plan
The high complexity is often necessary in the functions but could definitely be split up in many cases where specific use functionalities within the program could instead be function calls which would aid in creating abstractions but would of course add up to the same complexity number.  
   
This would be done by copying parts of the code for a specific purpose and instead creating a helper function that achieves the same purpose. This is exactly what we done with the group members aiming for P+. We observed what the parts of the code with a high number of branches with a specific purpose did and constructed functions with the correct arguments and return values so as to not change any functionality. 

### P+: Carried out refactoring and improved branch coverage with 4 tests:

#### Refactor: Cyclomatic Complexity improvement (P+):
The complete results can be found [here](./lib/matplotlib/lizardResAfter.txt)
```
================================================
  NLOC    CCN   token  PARAM  length  location  
------------------------------------------------
//Jonas's old result:
198     77   1724     17     462 hist@6492-6953@./axes/_axes.py
//Jonas's new result:
152     42   1195     17     383 hist@6710-7092@./axes/_axes.py

//Klara's old result:
119     30   1057     19     229 streamplot@18-246@./streamplot.py
//Klara's new result:
92      18    700     19     182 streamplot@90-271@./streamplot.py

//Pontus's old result
57     17    431      8     108 get_tight_layout_figure@194-301@./_tight_layout.py
//Pontus's new result
47     10    346      8     114 get_tight_layout_figure@220-333@./_tight_layout.py

//Ronan's old result:
65     22    397      2     221 subplot@1129-1349@lib/matplotlib\pyplot.py
//Ronan's new result:
42     13    259      2     166 subplot@1170-1335@lib/matplotlib\pyplot.py
```

#### Branch Coverage Improvement (P+):
The entire old result can be found [here](./lib/matplotlib/BranchCovResOld.txt) (before the new tests)  
The entire new result can be found [here](./lib/matplotlib/BranchCovRes.txt) (after the new tests)
```
DIY output: 
//Jonas's old result:
The hist() function took 81.69014084507043% of its branches, 58 out of 71, during the tests.
//Jonas's new result:
The hist() function took 88.73239436619718% of its branches, 63 out of 71, during the tests.


//Pontus's old result:
The table() function took 75.0% of its branches, 21 out of 28, during the tests.
//Pontus's new result:
The table() function took 89.28571428571429% of its branches, 25 out of 28, during the tests.


//Klara's old result:
The streamplot() function took 79.3103448275862% of its branches, 23 out of 29, during the tests.
//Klara's new result:
The streamplot() function took 93.10344827586206% of its branches, 27 out of 29, during the tests.

//Ronan's old result:
The subplot() function took 88.88888888888889% of its branches, 16 out of 18, during the tests.
//Ronan's new result:
The subplot() function took 100% of its branches, 18 out of 18, during the tests.
```

#### Jonas: 
Refactored the hist() function to decrease the cyclomatic complexity number from 77 to 42 (0.65 * 77 = 50.05 → more than 35% improvement) by taking three large parts with a specific purpose that included many branches and separating them into three different helper functions that reduced the complexity. 

Branch coverage was improved from 81% to 88.9% with four new tests that took inspiration from the previous tests and edited the function arguments and data structures before the function call to reach new branches. 

#### Klara:
Improved branch coverage of streamplot() with 4 new tests. The coverage went from 79% to 93%.

Refactored the streamplot function to reduce the cyclomatic complexity from CNN 30 to 18, a 35% improvement would have resulted in CCN 19.5, meaning the complexity was improved by more than 35%. 

#### Pontus

* Reduced the CCN from 17 -> 10 for the function get_tight_layout_figure() which is about 41% (get_tight_layout_figure@194-301@./_tight_layout.py) 
* and improved branch coverage with 4 new tests for the function table() (table@654-830@./table.py) from 75% -> 89%

#### Ronan

* Improved branch coverage of subplot() with one test case and of figure() with 3 new test cases.
* Reduced the CCN from 22 -> 13 for the subplot function() wich is about 41 % reduction.


## Coverage improvement

Show the comments that describe the requirements for the coverage.

Report of old coverage: The old coverage report can be found [here](./lib/matplotlib/Initialhtmlcov/index.html)

Report of new coverage: The new coverage report can be found [here](./lib/matplotlib/htmlcov/index.html)

#### Number of test cases added: two per team member (P) or at least four (P+).

Test cases added:  
Jonas:
My tests are in this [file](./lib/matplotlib/tests/test_axes_jonas.py):
* `test_hist_orientation_density_right()` 
* `test_hist_orientation_density_left()` 
* `test_hist_log_orientation_density()`
* `test_hist_log_orientation()`   
  
Klara:
My tests are in this [file](./lib/matplotlib/tests/test_streamplot_klara.py), they are: 
* `test_streamplot_color_grid_shapes_not_matching()`
* `test_streamplot_linewidth_grid_shape_not_matching()`
* `test_streamplot_linewidth_check_u_grid_shape_not_matching()`
* `test_streamplot_()`

Pontus: [file](./lib/matplotlib/tests/test_table.py)
Can be found further down in the file
* `test_table_no_args()`
* `test_table_wrong_rows()` 
* `test_table_wrong_columns()`
* `test_table_rowLabels_length()`

Ahmad: [file](./lib/matplotlib/tests/func_boxplot.py)
* `boxplot_test_empty_string()`
* `boxplot_test_patchArtist_color()`

Ronan: [file](./lib/matplotlib/tests/test_pyplot_ronan.py)
* `test_subplot_confused_with_subplots()`
* `test_figure_not_managed_by_pyplot`
* `test_figure_with_num_str`
* `test_figure_label_attributed`


## Self-assessment: Way-of-working

Current state according to the Essence standard: “Foundation established”

* The key practices and tools that form the foundation of the way-of-working are
selected.
  * Github, Discord, Lizard, Coverage
  * Commit templates and issue tracker
* Enough practices for work to start are agreed to by the team.
  * Yes we agree that we have enough
* All non-negotiable practices and tools have been identified.
  * Yes
* The gaps that exist between the practices and tools that are needed and the practices and tools that are available have been analyzed and understood.
   * Yes
* The capability gaps that exist between what is needed to execute the desired way of
working and the capability levels of the team have been analyzed and understood.
  * Yes
* The selected practices and tools have been integrated to form a usable way-of-working.
  * Yes. For example, although three of the team members have had problems building the repo, the way-of-working in these cases has been resolved.

#### How have you improved during the course?
We recently changed groups so nothing can really be said about the current group's improvement in working together. 

#### Where is there potential for improvement?
A lot of things can be done to improve where the main improvement probably lies in being able to fully work in parallel which was hindered mainly by the difficulties with building the chosen project for all group members but also communication.


## Overall experience

#### What are your main take-aways from this project? What did you learn?
Our main takeaways from this assignment is mostly grasping the complexity of very large code base. Writing test-cases for functions that you have not written yourself is very time-consuming and complicated, both to first understand the function and to make the test-case execute critical parts of the code.


## Statement of contribution:

Klara (aiming for P+): counted CCN by hand for _keypress and streamplot functions, implemented manual coverage measurement for streamplot, wrote 4 new tests for streamplot, improved the complexity of streamplot with at least 35%, wrote the report together with Jonas, Pontus and Ahmad.

Pontus: (aiming for P+) Wrote 4 new tests for the function table() (table@654-830@./table.py). Implemented manual branch coverage for the function get_tight_layout_figure(). Worked on the report


Ahmad: counted CCN by hand for _apply_params and plotbox() functions. In addition, implemented manual coverage for plotbox() functions. Wrote two tests for plotbox() and improved complexity. Also wrote the report with Klara, Jonas and Pontus.

Jonas (aiming for P+): Counted CCN by hand for the subsuper() function, wrote the DIY branch coverage tool, implemented manual branch coverage for the hist() function, wrote four new tests for the hist() function to improve branch coverage from 81% to 88.9%, refactored the hist() function from CCN 77-42, wrote the report together with Klara, Pontus and Ahmad.

Ronan (aiming for P+): counted CCN by hand for subplot() and figure() functions. In addition, implemented manual coverage for subplot() function. Wrote a test for subplot() and 3 for figure().